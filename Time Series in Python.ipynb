{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classes for time series analysis. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherReader:\n",
    "\n",
    "    \"\"\"This class will provide access to weather data (temperature, humidity etc).  Data will be retrieved as a \n",
    "    CSV file, but will be provided as a dataframe\"\"\"\n",
    "    \n",
    "    def __init__(self, path, weathertype):\n",
    "        'Get CSV file and transform into dataframe.  This assumes that only a .csv file will be given'\n",
    "        'path = directory path where data can be found'\n",
    "        'weathertype = choice of temp, humidity, or temp/humidity'\n",
    "        self.path = path\n",
    "        self.df_file = pd.read_csv(path, index_col='datetime', parse_dates=['datetime'])\n",
    "        self.weathertype = weathertype\n",
    "\n",
    "    def validations(self):\n",
    "        'Pre-processing steps go here'\n",
    "        \n",
    "        \n",
    "    def get_data(self, starttime, endtime):\n",
    "        \"\"\"Extract data from the weather dataframe using specific start and stop times.  Weathertype is temp,\n",
    "        humidity, etc\"\"\"\n",
    "        if self.weathertype == 'temp':\n",
    "            data_set = self.df_file[starttime:endtime].temp\n",
    "        elif self.weathertype == 'temp/humidity':\n",
    "            data_set = self.df_file[starttime:endtime].temp.append(self.df_file[starttime:endtime].humidity*100) \n",
    "        elif self.weathertype == 'humidity':\n",
    "            data_set = self.df_file[starttime:endtime].humidity*100\n",
    "        return data_set\n",
    "    \n",
    "    \n",
    "    def get_daily_data(self, date):\n",
    "        pd_date = pd.to_datetime(date)\n",
    "        'Returns 24 hours of weather data'\n",
    "        data =  self.get_data(date, date + pd.DateOffset(hours=23)).values\n",
    "        if len(data) != 24:\n",
    "                print('This date does not have 24 hours: ', date)\n",
    "                print('It has', len(data), 'hours')\n",
    "                print(\" \")\n",
    "        if len(data) > 24:\n",
    "            print(\"Removing extra hours\")\n",
    "            hours = date + pd.DateOffset(hours=23)\n",
    "            print(hours)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = WeatherReader('/home/KOSUWeather.csv', 'temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This date does not have 24 hours:  2015-11-01 00:00:00\n",
      "It has 25 hours\n",
      " \n",
      "Removing extra hours\n",
      "2015-11-01 23:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([52.77, 52.61, 52.87, 52.68, 52.87, 52.75, 52.68, 53.19, 53.24,\n",
       "       53.31, 54.92, 57.34, 60.41, 62.8 , 64.07, 64.73, 65.28, 64.42,\n",
       "       62.61, 59.14, 55.82, 54.24, 53.64, 51.98, 50.73])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('2015-11-01', '2015-11-02', freq='D')\n",
    "wr.get_daily_data(dates[0])\n",
    "#wr.get_data('2015-11-01 00:00:00', '2015-11-06 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class DictionaryBuilder:\n",
    "    \"\"\"Builds a dictionary of centroids and date values using a k-means algorithm\"\"\"\n",
    "    \n",
    "    def __init__(self, data_source, startdate, enddate, num_clust, num_iters):\n",
    "    \n",
    "        self.data_source = data_source            #weather data and dates from WeatherReader class\n",
    "        self.startdate = startdate                #start date for k-means processing\n",
    "        self.enddate = enddate                    #end date for k-means processing\n",
    "        self.num_clust = num_clust                #number of clusters wanted\n",
    "        self.num_iters = num_iters                #number of interations wanted            \n",
    "    \n",
    "    \n",
    "    def get_dates(self):\n",
    "        dates = pd.date_range(self.startdate, self.enddate, freq='D')  \n",
    "        np.random.shuffle(dates.values)\n",
    "        \n",
    "        tds = []\n",
    "        kept_dates = []\n",
    "        for d in dates:\n",
    "             # get the temperature time series for this date\n",
    "             ts = self.data_source.get_daily_data(d)\n",
    "             if len(ts) == 24:\n",
    "                 tds.append(ts)\n",
    "                 kept_dates.append(d)\n",
    "    \n",
    "\n",
    "    def euclid_dist(ts1, ts2):\n",
    "        euclid = np.sqrt(sum((ts1 - ts2)**2))\n",
    "        return euclid\n",
    "\n",
    "\n",
    "    def k_means(self, data, centroids):\n",
    "        import random\n",
    "    #     centroids = random.sample(data, num_clust)\n",
    "        counter = 0\n",
    "        for n in range(num_iter):\n",
    "            counter += 1\n",
    "            print(counter)\n",
    "            assignments = {}\n",
    "            for ind,i in enumerate(data):\n",
    "                min_dist = float('inf')\n",
    "                closest_clust = None\n",
    "                for c_ind,j in enumerate(centroids):\n",
    "                    cur_dist = euclid_dist(i,j)\n",
    "                    if cur_dist < min_dist:\n",
    "                        min_dist = cur_dist\n",
    "                        closest_clust = c_ind\n",
    "                if closest_clust in assignments:\n",
    "                    assignments[closest_clust].append(ind)\n",
    "                else:\n",
    "                    assignments[closest_clust] = [ind]  \n",
    "                        \n",
    "        # recalculate centroids\n",
    "        for key in assignments:\n",
    "            clust_sum = 0\n",
    "            for k in assignments[key]:\n",
    "                clust_sum = clust_sum + data[k]\n",
    "                print(centroids)\n",
    "            centroids[key] = [m/len(assignments[key]) for m in clust_sum]\n",
    "            \n",
    "        return centroids, assignments\n",
    "\n",
    "    \n",
    "    def create_dictionary(self):\n",
    "        init_clusts = random.sample(tds, num_clust)    #find data points for number of clusters\n",
    "        centroids, assignments = k_means(tds, self.num_clust, self.num_iters, init_clusts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = WeatherReader('/home/KOSUWeather.csv', 'temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DictionaryBuilder(ds, '2016-01-15', '2016-02-15', 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-01-15'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.startdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.num_clust"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
